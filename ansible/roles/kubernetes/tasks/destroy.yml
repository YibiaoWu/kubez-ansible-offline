---
- name: Reset kubernetes cluster
  become: true
  kube_toolbox:
    module_name: kubeadm
    module_args: "reset -f"
  when:
    - inventory_hostname in groups['kubernetes']

- name: Clean up for kubernetes worker dirs
  become: true
  file:
    path: "{{ item.dir }}"
    state: absent
  loop:
    - { dir: "{{ kube_application_dir }}" }
    - { dir: "{{ helm_charts_dir }}" }
    - { dir: "/etc/cni/net.d" }
    - { dir: "/root/.kube" }
    - { dir: "/etc/kubernetes/kubeadm-config.yaml" }
  when:
    - inventory_hostname in groups['kubernetes']

- name: Clean iptables or ipvsadm rules
  become: True
  shell: iptables -F && iptables -X && iptables -t nat -F && iptables -t nat -X && iptables -t mangle -F && iptables -t mangle -X && iptables -t raw -F && iptables -t raw -X && ipvsadm -C
  when:
    - inventory_hostname in groups['kubernetes']

# - name: Print destroy results
#   debug:
#     msg: >-
#       The reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d

#       The reset process does not reset or clean up iptables rules or IPVS tables.
#       If you wish to reset iptables, you must do so manually by using the "iptables" command.

#       If your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)
#       to reset your system's IPVS tables.

#       The reset process does not clean your kubeconfig files and you must remove them manually.
#       Please, check the contents of the $HOME/.kube/config file.

#       The reset process does not destroy haproxy and keepalived if enabled and you must stop them manually.
#   connection: local
#   run_once: True
